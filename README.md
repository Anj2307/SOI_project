
# ğŸ•µï¸â€â™‚ï¸ Fraud Detection Model ğŸ§ ğŸ“Š

Welcome to a complete exploratory data analysis (EDA) project aimed at uncovering fraud patterns from financial transaction data. This works on differnet parameters of fraud person. In this project I create Machine learning model to predict fraud automatically

---
# ğŸ“Š Data Analysis

## ğŸ—‚ï¸ Dataset Overview

- ğŸ“ **File**: `SOI_2025_Dataset.csv`
- ğŸ¯ **Target column**: `fraud_bool` (0 = Legit, 1 = Fraud)
- ğŸ“Š **Features analyzed**:
  - `credit_risk_score`
  - `bank_branch_count_8w`
  - `device_distinct_emails_8w`
  - `foreign_request`, `month`, `session_length_in_minutes`, `payment_type`
  - `prev_address_months_count`, `current_address_months_count`
  - `total_relationship_count`, `income`

---

## ğŸ” Key Insights & Findings

### ğŸ“ˆ Credit Risk Score
- ğŸš© Fraudsters had **unexpectedly higher credit scores**, possibly indicating **synthetic identity fraud** or stolen identities with good credit history.

### ğŸ¦ Bank Branch Usage (Last 8 Weeks)
- Fraudulent users typically had access to **fewer bank branches**, suggesting **online-only behavior** or **temporary accounts**.

### ğŸ’» Deviceâ€“Email Mapping
- Devices associated with **multiple distinct emails** were more likely linked to fraud â€” indicating **account farming** or **shared device abuse**.

### ğŸŒ Foreign Requests
- A clear fraud spike was observed in transactions with `foreign_request = 1`, supporting **geolocation-based risk** profiling.

### ğŸ—“ï¸ Monthly Trend
- ğŸ“† Fraud incidents peaked in **Month 7 (July)** â€” likely due to seasonal or quarter-end fraud trends.

### âŒ› Session Length
- Most fraudulent sessions were **short-lived** (low session length), hinting at **scripted** or **bot-like** behavior.

### ğŸ’» Device OS
- Fraud was disproportionately higher on **Windows OS**, likely due to ease of use for fraud tools and botnets.

### ğŸ”Œ Keep-Alive Sessions
- Fraudsters often had `keep_alive_session = 0`, suggesting **non-persistent activity** to avoid detection.

### ğŸ  Address Stability
- Fraudulent users often had **very short** or **missing previous address durations**, indicating a lack of verifiable residential history.

### ğŸ’° Income Trends
- Users with **missing or low income values** were slightly more fraud-prone.
- Could also indicate **fake identity data entries**.

### ğŸ§¾ Total Relationships
- Lower `total_relationship_count` suggests **new, potentially fake accounts** used solely for fraud.

### ğŸ’³ Payment Types
- Certain `payment_type` values (like prepaid cards) saw **higher fraud rates**, indicating misuse of anonymous or quick-transfer payment methods.

---

## ğŸ“Š Visualizations Included

- ğŸ“¦ Boxplots for feature distributions
- ğŸ“‰ Fraud rate bar charts by:
  - Month
  - Device type
  - Bank branch access
- ğŸ“ Countplots of fraud vs foreign access, OS, and payment type

ğŸ–¼ï¸ All charts are embedded in [`data_analysis.ipynb`](./data_analysis.ipynb)

---
## ğŸ§± Feature Engineering

We enhanced the dataset to better represent risk factors:

### 1: ğŸ  Address Stability

- Replaced `-1` in `prev_address_months_count` and `current_address_months_count`  with median of respective columns

### 2: ğŸ’³ Encoded Categorical Features

- Label-encoded: `payment_type`, `employment_type`, `device_os`,`housing_status` etc.
- Saved mappings to `mappings.json`

### 3: ğŸš€ Velocity Risk Features

- Standardized and log-transformed: `velocity_6h`, `velocity_8h`, `velocity_1w`
- Created `velocity_risk_score` with `weights` saved to `weight_map(2).json`.

### 4: ğŸ“ Standerdize the data

- Transformed: `Data is transformed or scaled in all categories`
### 5: ğŸ“ Create test and train datasets for model creation

- `Have created train_test_split data`
---
All feature engineering code are embedded in [`feature engineering`](./feature_engineering.ipynb)
## ğŸ“ Project Structure

```
fraud_detect/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ SOI_2025_Dataset.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_analysis.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”œâ”€â”€ mappings/
â”‚   â”œâ”€â”€ mappings.json
â”‚   â””â”€â”€ weight_map(2).json
â”œâ”€â”€ plots/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```


---

## âš™ï¸ Technologies Used

- ğŸ Python 3.x, json
- ğŸ“Š Pandas, NumPy,sckitlearn
- ğŸ¨ Matplotlib, Seaborn
- ğŸ§  Jupyter Notebook
  

---

## ğŸš€ How to Run This Project

1. ğŸ“¥ Clone the repository:
   ```bash
   git clone https://github.com/Anj2307/fraud_detect.git
   cd fraud_detect
   ```

2. ğŸ”§ Install dependencies:
   ```bash
   pip install -r requirements.txt
   pip install json
   ```

3. â–¶ï¸ Launch the notebook:
   ```bash
   jupyter notebook data_analysis.ipynb
   jupyter notebook feature_engineering.ipynb
   ```
---

## ğŸ“Œ Next Steps

- ğŸ¤– Build fraud classification models: Logistic Regression, XGBoost, etc.
- ğŸ“ˆ Evaluate metrics: Precision, Recall, AUC-ROC
- ğŸŒ Deploy via API or real-time scoring service

---

## ğŸ¤ Contributions

ğŸ§‘â€ğŸ’» Pull requests and forks are welcome!  
If you have new analysis ideas or want to improve modeling, feel free to contribute.

---

## ğŸ‘¤ Author

Developed by: **Anubhav Goyal**  
ğŸ“ B.Tech (Mathematics and Computing) @ IIT Dharwad  
ğŸ“¬ GitHub: [@Anj2307](https://github.com/Anj2307)

---

> ğŸ“ *This project is part of a learning journey in AI, Finance, and Machine Learning applied to fraud detection.*
