
# ğŸ•µï¸â€â™‚ï¸ Fraud Detection on Financial Transactions Using Machine Learning ğŸ§ ğŸ“Š

Welcome to a complete exploratory data analysis (EDA) project aimed at uncovering fraud patterns from financial transaction data. This project works on different parameters of fraudulent users. A machine learning model is created to automatically predict fraud based on historical data.

---

# ğŸ“Š Data Analysis

## ğŸ—‚ï¸ Dataset Overview

* ğŸ“ **File**: `SOI_2025_Dataset.csv`
* ğŸ¯ **Target column**: `fraud_bool` (0 = Legit, 1 = Fraud)
* ğŸ“Š **Features analyzed**:
  * `credit_risk_score`, `bank_branch_count_8w`, `device_distinct_emails_8w`
  * `foreign_request`, `month`, `session_length_in_minutes`, `payment_type`
  * `prev_address_months_count`, `current_address_months_count`
  * `total_relationship_count`, `income`

---

## ğŸ” Key Insights & Findings

### ğŸ“ˆ Credit Risk Score
* ğŸš© Fraudsters had **unexpectedly higher credit scores**, possibly indicating **synthetic identity fraud** or stolen identities.

### ğŸ¦ Bank Branch Usage
* Fewer branches used by fraudsters â€” suggesting **online-only** or **temporary accounts**.

### ğŸ’» Deviceâ€“Email Mapping
* Devices linked to multiple emails â†’ likely **account farming** or **bot usage**.

### ğŸŒ Foreign Requests
* `foreign_request = 1` showed higher fraud â€” useful for **geolocation profiling**.

### ğŸ—“ï¸ Monthly Trend
* Spike in **Month 7 (July)** â€” possibly seasonal or reporting-cycle-related fraud.

### âŒ› Session Length
* Fraudulent sessions were **short** â€” possible **automation** or **scripted behavior**.

### ğŸ’» Device OS
* Fraud was higher on **Windows OS** â€” potentially due to botnet/tool accessibility.

### ğŸ”Œ Keep-Alive Sessions
* `keep_alive_session = 0` frequent in frauds â€” indicating **non-persistent** behavior.

### ğŸ  Address Stability
* Many fraudsters had **missing/low residence durations** â€” hard to verify identity.

### ğŸ’° Income Trends
* **Low/missing income values** had slightly more frauds â€” indicating **fake profiles**.

### ğŸ§¾ Total Relationships
* Fewer relationships = newer/temporary/fake accounts used for fraud.

### ğŸ’³ Payment Types
* Prepaid/anonymous cards saw higher fraud rates.

---

## ğŸ“Š Visualizations Included

* Boxplots, bar charts and countplots showing fraud patterns across:
  * Month, OS, payment type, device type, foreign requests, etc.
* ğŸ“ Embedded in: [`data_analysis.ipynb`](./notebooks/01_data_analysis.ipynb)

---

# ğŸ§± Feature Engineering

### ğŸ  Address Stability
* `-1` replaced with column medians for `prev_address_months_count`, `current_address_months_count`

### ğŸ’³ Encoded Categorical Features
* Label-encoded: `payment_type`, `employment_type`, `device_os`, etc.
* Saved mappings to `mappings.json`

### ğŸš€ Velocity Risk Features
* Transformed: `velocity_6h`, `velocity_8h`, `velocity_1w` with log scaling
* Created `velocity_risk_score` using weighted score map

### âœï¸ Data Standardization
* Features normalized or scaled

### ğŸ§ª Train-Test Split
* Used `train_test_split` to prepare model datasets

ğŸ““ Code in: [`feature_Engineering.ipynb`](./notebooks/02_feature_engineering.ipynb)

---

## ğŸ“ Project Structure

```
fraud_detect/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ SOI_2025_Dataset.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_analysis.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ logistic_model.ipynb
â”‚   â”œâ”€â”€ lightGBM.ipynb
â”‚   â””â”€â”€ XG_boost_part2.ipynb
â”œâ”€â”€ mappings/
â”‚   â”œâ”€â”€ mappings.json
â”‚   â””â”€â”€ weight_map(2).json
â”œâ”€â”€ models/                  # Saved models
â”œâ”€â”€ plots/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Technologies Used

* ğŸ Python 3.x, JSON
* ğŸ“Š Pandas, NumPy, Scikit-learn, XGBoost, LightGBM
* ğŸ¨ Matplotlib, Seaborn
* ğŸ§  Jupyter Notebook

---

# ğŸ¤– Model Building & Evaluation

### 1ï¸âƒ£ Logistic Regression
* `sklearn.linear_model.LogisticRegression`
* Scaled numeric + encoded categorical features
* ğŸ“ˆ ROC Curve, Confusion Matrix, F1-score
* ğŸ““ [`logistic_model.ipynb`](./notebooks/logistic_model.ipynb)

### 2ï¸âƒ£ XGBoost Classifier
* `xgboost.XGBClassifier`
* Tuned parameters, tree ensembles
* Feature importance plots
* ğŸ““ [`XG_boost_part2.ipynb`](./notebooks/XG_boost_part2.ipynb)

### 3ï¸âƒ£ LightGBM Classifier
* `lightgbm.LGBMClassifier`
* Faster gradient boosting
* ğŸ““ [`lightGBM.ipynb`](./notebooks/lightGBM.ipynb)

---
## ğŸ”§ Upcoming Improvements

* Cross-validation for robustness
* Better handling of imbalance via:
  * `class_weight='balanced'`
  * SMOTE, undersampling
* Model ensembling to boost recall

---

## ğŸ§  Conclusion

This project explored fraudulent financial behaviors via EDA, feature engineering, and predictive modeling. It highlights the importance of precision, interpretability, and class balancing in real-world fraud detection. Further improvements can increase model generalization and deployment readiness.

---

## ğŸ‘¤ Author

Developed by: **Anubhav Goyal**  
ğŸ“ B.Tech (Mathematics and Computing) @ IIT Dharwad  
ğŸ“¬ GitHub: [@Anj2307](https://github.com/Anj2307)  
ğŸ“¨ Email: [MC24BT005@iitdh.ac.in](mailto:MC24BT005@iitdh.ac.in)

> ğŸ“ *This project is part of a learning journey in AI, Finance, and Machine Learning applied to fraud detection.*
